{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "total_series_length  = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is x:\n",
      "(5, 10000)\n",
      "this is y:\n",
      "(5, 10000)\n"
     ]
    }
   ],
   "source": [
    "x,y = generateData()\n",
    "print('this is x:')\n",
    "print(x.shape)\n",
    "print('this is y:')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "\n",
    "W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_5:0\", shape=(5, 4), dtype=float32)\n",
      "Tensor(\"unstack_2:0\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:1\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:2\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:3\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:4\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:5\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:6\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:7\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:8\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:9\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:10\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:11\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:12\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:13\", shape=(5,), dtype=float32)\n",
      "Tensor(\"unstack_2:14\", shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(init_state)\n",
    "for i in inputs_series:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_state = init_state\n",
    "states_series = []\n",
    "for current_input in inputs_series: \n",
    "    #print(current_input)\n",
    "    current_input = tf.reshape(current_input, [batch_size,1])\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state], 1)\n",
    "    \n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W)+b)\n",
    "    #print(next_state)\n",
    "    states_series.append(next_state)\n",
    "    current_state = next_state\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(states_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits_series = [tf.matmul(state, W2)+b2 for state in states_series]\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "#print(type(logits_series))\n",
    "#print(type(labels_series))\n",
    "#print(type(zip(logits_series, labels_series)))\n",
    "#for i in zip(logits_series, labels_series):\n",
    " #   print(i)\n",
    "#zip takes the two lists and makes tuples at each index\n",
    "#this zip makes a bunch of tuples of tensors that are in logits and labels series\n",
    "    \n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=labels) for logits,labels in zip(logits_series, labels_series)]      \n",
    "    \n",
    "#the logits = logits and labels = labels comes from the for loop in the list\n",
    "#comprehension on the line above \n",
    "\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "    \n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])    \n",
    "        plt.subplot(2,3, batch_series_idx +2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length) \n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width = 1, color = 'blue')\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width = 1, color = 'red')\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width = 1, color = 'greeen')\n",
    "        \n",
    "        \n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "    '''\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f6e9ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.695852\n",
      "Step 100 Loss 0.700539\n",
      "Step 200 Loss 0.73129\n",
      "Step 300 Loss 0.691167\n",
      "Step 400 Loss 0.697235\n",
      "Step 500 Loss 0.694921\n",
      "Step 600 Loss 0.691318\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.704151\n",
      "Step 100 Loss 0.696035\n",
      "Step 200 Loss 0.695234\n",
      "Step 300 Loss 0.689879\n",
      "Step 400 Loss 0.611907\n",
      "Step 500 Loss 0.119075\n",
      "Step 600 Loss 0.0260856\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.18221\n",
      "Step 100 Loss 0.009095\n",
      "Step 200 Loss 0.00624204\n",
      "Step 300 Loss 0.00451931\n",
      "Step 400 Loss 0.00370049\n",
      "Step 500 Loss 0.00308849\n",
      "Step 600 Loss 0.00251373\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.189032\n",
      "Step 100 Loss 0.00256\n",
      "Step 200 Loss 0.00190524\n",
      "Step 300 Loss 0.00176416\n",
      "Step 400 Loss 0.00173824\n",
      "Step 500 Loss 0.00147863\n",
      "Step 600 Loss 0.00144714\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.182415\n",
      "Step 100 Loss 0.00128079\n",
      "Step 200 Loss 0.00130863\n",
      "Step 300 Loss 0.00124915\n",
      "Step 400 Loss 0.0012065\n",
      "Step 500 Loss 0.00118186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-895a49b2e64a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mbatchX_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mbatchY_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0m_current_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 })\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f023630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d749ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0, 10000) for Tensor 'Placeholder_4:0', which has shape '(5, 15)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3e362e9f792e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                                                           \u001b[0mbatchX_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                                                           \u001b[0mbatchY_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                                                                           \u001b[0minit_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                                                                                       })\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicholastorba/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0, 10000) for Tensor 'Placeholder_4:0', which has shape '(5, 15)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "        \n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "            \n",
    "            batchX = x[:, start_idx:end_idx]\n",
    "            batchY = y[: start_idx: end_idx]\n",
    "            \n",
    "            _totoal_loss, _train_step, _current_state, _predictions_series = sess.run([total_loss, train_step, current_state, predictions_series],\n",
    "                                                                                      feed_dict = {\n",
    "                                                                                          batchX_placeholder:batchX,\n",
    "                                                                                          batchY_placeholder:batchY,\n",
    "                                                                                          init_state:current_state\n",
    "                                                                                      })\n",
    "            loss_list.append(_total_loss)\n",
    "            \n",
    "            if batch_idx%100 ==0:\n",
    "                print(\"Step\", batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "                \n",
    "plot.ioff()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
